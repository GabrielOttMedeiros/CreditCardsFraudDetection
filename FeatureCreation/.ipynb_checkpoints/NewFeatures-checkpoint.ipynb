{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a38cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "## importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance \n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "## Here we set the directory to look up the folder containing the data\n",
    "os.chdir(\"/Users/gabrielmedeiros/Documents/OneDrive/Business analytics/DATA_445_Machine_Learning\")\n",
    "\n",
    "\n",
    "## Reading csv file, index_col = 0 makes the first column of the data to become the index of our pandas data frame\n",
    "train_data = pd.read_csv('fraudTrain.csv', index_col = 0)\n",
    "test_data = pd.read_csv('fraudTest.csv', index_col = 0)\n",
    "\n",
    "#########################\n",
    "## FEATURE ENGINEERING ##\n",
    "#########################\n",
    "\n",
    "## Here assign to n the amount of observations we have in the dataset\n",
    "n = train_data.shape[0]\n",
    "\n",
    "##############\n",
    "## Distance ##\n",
    "##############\n",
    "\n",
    "## Creating empty list to store the reuslts\n",
    "distance_to_append = []\n",
    "\n",
    "## Looping through each row an computing the distance between transaction address and merchants address\n",
    "for i in range(0,n):\n",
    "\n",
    "    ## Here we gather the lat and long from the transaciton address\n",
    "    coords_1 = (train_data['lat'][i], train_data['long'][i])\n",
    "\n",
    "    ## Here we gather the lat and long from the merchants address\n",
    "    coords_2 = (train_data['merch_lat'][i], train_data['merch_long'][i])\n",
    "\n",
    "    ## Here we compute the disance in miles between the locations\n",
    "    distance_to_append.append(geopy.distance.geodesic(coords_1, coords_2).miles)\n",
    "\n",
    "## Adding results to our data set\n",
    "train_data['distance'] = distance_to_append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f398f",
   "metadata": {},
   "source": [
    "## Feature Engineering train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab08e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## AVG Distance by Category##\n",
    "#############################\n",
    "\n",
    "## Here we create a groupby function to get the mean distance by each category\n",
    "avg_dist_by_category = pd.DataFrame(train_data.groupby(['cc_num','category'])['distance'].mean())\n",
    "\n",
    "## Here we create a temporary column holding our index values (cc_num)\n",
    "avg_dist_by_category['columns'] = avg_dist_by_category.index\n",
    "\n",
    "## Here we drop our temporary column and reset our index, which was previously our cc_num\n",
    "avg_dist_by_category = avg_dist_by_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns of the groupby function\n",
    "avg_dist_by_category.columns = ['cc_num','category','avg_distance_by_category']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "train_data = avg_dist_by_category.merge(train_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e325b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## AVG Distance ##\n",
    "##################\n",
    "\n",
    "## Here we create a groupby function to get the mean distance by each category\n",
    "avg_dist = pd.DataFrame(train_data.groupby(['cc_num'])['distance'].mean())\n",
    "\n",
    "## Here we create a temporary column holding our index values (cc_num)\n",
    "avg_dist['columns'] = avg_dist.index\n",
    "\n",
    "## Here we drop our temporary column and reset our index, which was previously our cc_num\n",
    "avg_dist = avg_dist.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns of the groupby function\n",
    "avg_dist.columns = ['cc_num','avg_distance']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "train_data = avg_dist.merge(train_data, on = ['cc_num'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d2f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "## Age ##\n",
    "#########\n",
    "\n",
    "## Creating empty list to store the resutls\n",
    "ages_to_append = []\n",
    "\n",
    "## Looping through each observation and computing the age of each individual from its DOB\n",
    "for i in range(0,n):\n",
    "\n",
    "    ## Here we add the last date of this year\n",
    "    year_of_2021 = datetime.strptime('2021-12-31', \"%Y-%m-%d\")\n",
    "\n",
    "    ## Here we call each DOB in the dataset\n",
    "    dob = datetime.strptime(train_data.dob[i], \"%Y-%m-%d\")\n",
    "\n",
    "    ## Here we compute the ages\n",
    "    ages_to_append.append(relativedelta(year_of_2021, dob).years)\n",
    "\n",
    "## Adding results to our data set\n",
    "train_data['age'] = ages_to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b64cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## Days of the Week ##\n",
    "######################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "dates = pd.to_datetime(train_data['trans_date_trans_time'])\n",
    "\n",
    "## Here we use our library to get the day of the week based on the transformed column\n",
    "train_data['day_of_week'] = dates.dt.day_name()\n",
    "\n",
    "##################\n",
    "## Uses per day ##\n",
    "##################\n",
    "\n",
    "## Here we create a dataframe containing the uses by day per card\n",
    "uses_per_day = pd.DataFrame(train_data.groupby('cc_num')['day_of_week'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_day['columns'] = uses_per_day.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_day.columns = ['uses_per_day','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_day = uses_per_day.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = uses_per_day.merge(train_data, on = ['cc_num', 'day_of_week'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1968918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## Month of the year ##\n",
    "#######################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "months = pd.to_datetime(train_data['trans_date_trans_time'])\n",
    "\n",
    "## Here we use our library to get the month of the year based on the transformed column\n",
    "train_data['month'] = dates.dt.month\n",
    "\n",
    "####################\n",
    "## Uses per month ##\n",
    "####################\n",
    "\n",
    "## Here we create a dataframe containing the card uses by month\n",
    "uses_per_month = pd.DataFrame(train_data.groupby('cc_num')['month'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_month['columns'] = uses_per_month.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_month.columns = ['uses_per_month','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_month = uses_per_month.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = uses_per_month.merge(train_data, on = ['cc_num','month'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b95ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Hour of the day ##\n",
    "#####################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "hour_of_the_day = []\n",
    "\n",
    "## Here we loop throough each observation, change the format of the items in each column, \n",
    "## and retrieve the hour of the day\n",
    "for i in range(0,n):\n",
    "    hour_of_the_day.append(datetime.strptime(train_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\").hour)\n",
    "\n",
    "## Here we attribute our results to a column\n",
    "train_data['hour_of_the_day'] = hour_of_the_day\n",
    "\n",
    "###################\n",
    "## Uses per hour ##\n",
    "###################\n",
    "\n",
    "## Here we create a dataframe containing the card uses by hour of day\n",
    "uses_per_hour = pd.DataFrame(train_data.groupby('cc_num')['hour_of_the_day'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_hour['columns'] = uses_per_hour.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_hour.columns = ['uses_per_hour','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_hour = uses_per_hour.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = uses_per_hour.merge(train_data, on = ['cc_num','hour_of_the_day'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293460c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## Total card uses by customer ##\n",
    "#################################\n",
    "\n",
    "## Here we get the number of transactions shown in the data set per card\n",
    "Uses = pd.DataFrame(train_data['cc_num'].value_counts())\n",
    "\n",
    "## Here we create a column to keep our cc_num\n",
    "Uses['cc_number2'] = Uses.index\n",
    "\n",
    "## Here we reset our index\n",
    "Uses = Uses.reset_index(drop = True)\n",
    "\n",
    "## Here we rename our columns\n",
    "Uses.columns = ['total_uses','cc_num']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "train_data = Uses.merge(train_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7013e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Total card uses by customer grouping ##\n",
    "##########################################\n",
    "\n",
    "conditions = [\n",
    "    (train_data['total_uses'] < 400),\n",
    "    (train_data['total_uses'] > 400) & (train_data['total_uses'] < 900),\n",
    "    (train_data['total_uses'] > 900) & (train_data['total_uses'] < 1200),\n",
    "    (train_data['total_uses'] > 1200) & (train_data['total_uses'] < 1800),\n",
    "    (train_data['total_uses'] > 1800) & (train_data['total_uses'] < 2200),\n",
    "    (train_data['total_uses'] > 2200) & (train_data['total_uses'] < 2800),\n",
    "    (train_data['total_uses'] > 2800) & (train_data['total_uses'] < 3200)]\n",
    "\n",
    "    \n",
    "classes = [\n",
    "    'LESS THAN 400',\n",
    "    'BETWEEN 400 AND 900',\n",
    "    'BETWEEN 900 AND 1200',\n",
    "    'BETWEEN 1200 AND 1800',\n",
    "    'BETWEEN 1800 AND 2200',\n",
    "    'BETWEEN 2200 AND 2800',\n",
    "    'BETWEEN 2800 AND 3200'\n",
    "    ]\n",
    "train_data['transactions_group'] = np.select(conditions,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08c0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Difference in minutes between each transaction ##\n",
    "####################################################\n",
    "\n",
    "## Here we create a list to hold our results\n",
    "new_time = []\n",
    "\n",
    "## Here we loop through each observation and transform the format of our data\n",
    "for i in range(0,n):\n",
    "    new_time.append(datetime.strptime(train_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "## Here we create a column containing transformed data to compute the difference in minutes\n",
    "## New format was recquired for the library to work\n",
    "train_data['transformed_time'] = new_time\n",
    "\n",
    "train_data = train_data.sort_values(by = 'transformed_time', ascending = True)\n",
    "\n",
    "## Here we compute the difference in minutes between each transacion\n",
    "train_data['diff_by_card_trans'] = train_data.groupby('cc_num')\\\n",
    "                              ['transformed_time'].diff().apply(lambda x: \\\n",
    "                              x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a01cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## AVG payment by category ##\n",
    "#############################\n",
    "\n",
    "## Here we create a dataframe containing the avg amount per category\n",
    "amt_per_category = pd.DataFrame(train_data.groupby(['cc_num','category'])['amt'].mean())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_per_category['columns'] = amt_per_category.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_per_category = amt_per_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_per_category.columns = ['cc_num','category','avg_by_category']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = amt_per_category.merge(train_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dce19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## AVG amount spent per card ##\n",
    "###############################\n",
    "\n",
    "## Here we create a dataframe containing the avg amount spent per card\n",
    "avg_amt = pd.DataFrame(train_data.groupby('cc_num')['amt'].mean())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "avg_amt['columns'] = avg_amt.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "avg_amt = avg_amt.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "avg_amt.columns = ['cc_num', 'avg_amt']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = avg_amt.merge(train_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f6c3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "## First and last purchase of each credit card ##\n",
    "#################################################\n",
    "\n",
    "## Here we extract the first and last transaction time recorded for each credit card\n",
    "temp_cc_time_max = pd.DataFrame(train_data.groupby('cc_num')['trans_date_trans_time'].max())\n",
    "temp_cc_time_min = pd.DataFrame(train_data.groupby('cc_num')['trans_date_trans_time'].min())\n",
    "\n",
    "## Here we assign the index(cc_num) to a column\n",
    "temp_cc_time_max['columns'] = temp_cc_time_max.index\n",
    "temp_cc_time_min['columns'] = temp_cc_time_min.index\n",
    "\n",
    "## Here we reset the index\n",
    "temp_cc_time_max = temp_cc_time_max.reset_index().drop(columns = 'columns')\n",
    "temp_cc_time_min = temp_cc_time_min.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "temp_cc_time_max.columns = ['cc_num','max_date']\n",
    "temp_cc_time_min.columns = ['cc_num','min_date']\n",
    "\n",
    "## Here we merge the new columns to our original data\n",
    "train_data = temp_cc_time_max.merge(train_data, on = 'cc_num', how = 'left')\n",
    "train_data = temp_cc_time_min.merge(train_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb194bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "## Diffefence in time between first and last purchase for each credit card ##\n",
    "#############################################################################\n",
    "\n",
    "## Here we transform the date type for each column\n",
    "min_dates = pd.to_datetime(train_data.min_date) \n",
    "max_dates = pd.to_datetime(train_data.max_date)\n",
    "\n",
    "## Here we compute the diff in minutes between first and last purchase\n",
    "diff_in_time = max_dates - min_dates\n",
    "\n",
    "## Here we create a dataframe with our results\n",
    "temp_data = pd.DataFrame(diff_in_time)\n",
    "\n",
    "## Here we add our results to a column in our data\n",
    "train_data['diff_first_last'] = temp_data.apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b9b0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## STD amount per card ##\n",
    "#########################\n",
    "\n",
    "## Here we create a dataframe containing the std from amount spent per card\n",
    "amt_std = pd.DataFrame(train_data.groupby('cc_num')['amt'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'std_amt']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = amt_std.merge(train_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75743c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "## STD amount per card by category ##\n",
    "#####################################\n",
    "\n",
    "## Here we create a dataframe containing the std from amount spent per card by category\n",
    "amt_std = pd.DataFrame(train_data.groupby(['cc_num','category'])['amt'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num','category', 'std_amt_by_category']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = amt_std.merge(train_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3a67cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## STD distance per card by category ##\n",
    "#######################################\n",
    "\n",
    "## Here we create a dataframe containing the std distance per card by category\n",
    "amt_std = pd.DataFrame(train_data.groupby(['cc_num','category'])['distance'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'category','std_dist_by_category']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = amt_std.merge(train_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "042d9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## STD distance per card ##\n",
    "###########################\n",
    "\n",
    "## Here we create a dataframe containing the std distance per card by category\n",
    "amt_std = pd.DataFrame(train_data.groupby('cc_num')['distance'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'std_dist']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = amt_std.merge(train_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1341888",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Purhase amt and dist > avg and > (1,2) std ##\n",
    "################################################\n",
    "\n",
    "## Here we create a binary column containing 0 if amount spent is less than avg amount\n",
    "train_data['purchase_>_avg'] = np.where(train_data['amt'] > train_data['avg_amt'],1,0)\n",
    "\n",
    "## Here we create a binary column containing 0 if amount spent is less than avg amount per category\n",
    "train_data['purchase_>_avg_by_category'] = np.where(train_data['amt'] > train_data['avg_by_category'],1,0)\n",
    "\n",
    "## Here we create a binary column containing 0 if distance is less than avg distance\n",
    "train_data['purchase_>_distance'] = np.where(train_data['distance'] > train_data['avg_distance'],1,0)\n",
    "\n",
    "## Here we create a binary column containing 0 if distance is less than avg distance by category\n",
    "train_data['purchase_>_distance_by_category'] = np.where(train_data['distance'] > train_data['avg_distance_by_category'],1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the amount spent is higher than 1 std\n",
    "train_data['amt_>_1_std'] = np.where(train_data.amt > (train_data.avg_amt + train_data.std_amt),1,0)\n",
    "## Here we classify if the amount spent is higher than 2 std\n",
    "train_data['amt_>_2_std'] = np.where(train_data.amt > (train_data.avg_amt + 2*train_data.std_amt),1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the amount spent by category is higher than 1 std\n",
    "train_data['amt_>_1_std_by_cagegory'] = np.where(train_data.amt > (train_data.avg_by_category + train_data.std_amt_by_category),1,0)\n",
    "## Here we classify if the amount spent by category is higher than 2 std\n",
    "train_data['amt_>_2_std_by_cagegory'] = np.where(train_data.amt > (train_data.avg_by_category + 2*train_data.std_amt_by_category),1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the distance is higher than 1 std\n",
    "train_data['dist_>_1_std'] = np.where(train_data.distance > (train_data.avg_distance + train_data.std_dist),1,0)\n",
    "## Here we classify if the distance is higher than 2 std\n",
    "train_data['dist_>_2_std'] = np.where(train_data.distance > (train_data.avg_distance + 2*train_data.std_dist),1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the distance by category is higher than 1 std\n",
    "train_data['dist_>_1_std_by_cagegory'] = np.where(train_data.distance > (train_data.avg_distance_by_category + train_data.std_dist_by_category),1,0)\n",
    "## Here we classify if the dintance by category is higher than 2 std\n",
    "train_data['dist_>_2_std_by_cagegory'] = np.where(train_data.distance > (train_data.avg_distance_by_category + 2*train_data.std_dist_by_category),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7d3dfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>category</th>\n",
       "      <th>uses_per_category</th>\n",
       "      <th>std_dist</th>\n",
       "      <th>std_dist_by_category</th>\n",
       "      <th>std_amt_by_category</th>\n",
       "      <th>std_amt</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>avg_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>purchase_&gt;_distance</th>\n",
       "      <th>purchase_&gt;_distance_by_category</th>\n",
       "      <th>amt_&gt;_1_std</th>\n",
       "      <th>amt_&gt;_2_std</th>\n",
       "      <th>amt_&gt;_1_std_by_cagegory</th>\n",
       "      <th>amt_&gt;_2_std_by_cagegory</th>\n",
       "      <th>dist_&gt;_1_std</th>\n",
       "      <th>dist_&gt;_2_std</th>\n",
       "      <th>dist_&gt;_1_std_by_cagegory</th>\n",
       "      <th>dist_&gt;_2_std_by_cagegory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>223</td>\n",
       "      <td>17.702489</td>\n",
       "      <td>16.89517</td>\n",
       "      <td>14.935356</td>\n",
       "      <td>122.632635</td>\n",
       "      <td>2019-01-01 12:47:15</td>\n",
       "      <td>2020-06-21 08:54:21</td>\n",
       "      <td>56.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>223</td>\n",
       "      <td>17.702489</td>\n",
       "      <td>16.89517</td>\n",
       "      <td>14.935356</td>\n",
       "      <td>122.632635</td>\n",
       "      <td>2019-01-01 12:47:15</td>\n",
       "      <td>2020-06-21 08:54:21</td>\n",
       "      <td>56.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>223</td>\n",
       "      <td>17.702489</td>\n",
       "      <td>16.89517</td>\n",
       "      <td>14.935356</td>\n",
       "      <td>122.632635</td>\n",
       "      <td>2019-01-01 12:47:15</td>\n",
       "      <td>2020-06-21 08:54:21</td>\n",
       "      <td>56.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>223</td>\n",
       "      <td>17.702489</td>\n",
       "      <td>16.89517</td>\n",
       "      <td>14.935356</td>\n",
       "      <td>122.632635</td>\n",
       "      <td>2019-01-01 12:47:15</td>\n",
       "      <td>2020-06-21 08:54:21</td>\n",
       "      <td>56.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>223</td>\n",
       "      <td>17.702489</td>\n",
       "      <td>16.89517</td>\n",
       "      <td>14.935356</td>\n",
       "      <td>122.632635</td>\n",
       "      <td>2019-01-01 12:47:15</td>\n",
       "      <td>2020-06-21 08:54:21</td>\n",
       "      <td>56.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cc_num       category  uses_per_category   std_dist  \\\n",
       "0  60416207185  gas_transport                223  17.702489   \n",
       "1  60416207185  gas_transport                223  17.702489   \n",
       "2  60416207185  gas_transport                223  17.702489   \n",
       "3  60416207185  gas_transport                223  17.702489   \n",
       "4  60416207185  gas_transport                223  17.702489   \n",
       "\n",
       "   std_dist_by_category  std_amt_by_category     std_amt             min_date  \\\n",
       "0              16.89517            14.935356  122.632635  2019-01-01 12:47:15   \n",
       "1              16.89517            14.935356  122.632635  2019-01-01 12:47:15   \n",
       "2              16.89517            14.935356  122.632635  2019-01-01 12:47:15   \n",
       "3              16.89517            14.935356  122.632635  2019-01-01 12:47:15   \n",
       "4              16.89517            14.935356  122.632635  2019-01-01 12:47:15   \n",
       "\n",
       "              max_date    avg_amt  ...  purchase_>_distance  \\\n",
       "0  2020-06-21 08:54:21  56.023366  ...                    1   \n",
       "1  2020-06-21 08:54:21  56.023366  ...                    0   \n",
       "2  2020-06-21 08:54:21  56.023366  ...                    1   \n",
       "3  2020-06-21 08:54:21  56.023366  ...                    1   \n",
       "4  2020-06-21 08:54:21  56.023366  ...                    0   \n",
       "\n",
       "   purchase_>_distance_by_category  amt_>_1_std  amt_>_2_std  \\\n",
       "0                                1            0            0   \n",
       "1                                0            0            0   \n",
       "2                                1            0            0   \n",
       "3                                1            0            0   \n",
       "4                                0            0            0   \n",
       "\n",
       "   amt_>_1_std_by_cagegory  amt_>_2_std_by_cagegory dist_>_1_std  \\\n",
       "0                        0                        0            1   \n",
       "1                        1                        0            0   \n",
       "2                        0                        0            0   \n",
       "3                        0                        0            1   \n",
       "4                        0                        0            0   \n",
       "\n",
       "   dist_>_2_std  dist_>_1_std_by_cagegory  dist_>_2_std_by_cagegory  \n",
       "0             0                         1                         0  \n",
       "1             0                         0                         0  \n",
       "2             0                         0                         0  \n",
       "3             0                         1                         0  \n",
       "4             0                         0                         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "## Uses per category ##\n",
    "#######################\n",
    "\n",
    "## Here we create a dataframe containing the uses by category per card\n",
    "uses_per_category = pd.DataFrame(train_data.groupby('cc_num')['category'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_category['columns'] = uses_per_category.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_category.columns = ['uses_per_category','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_category = uses_per_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "train_data = uses_per_category.merge(train_data, on = ['cc_num','category'], how = 'left')\n",
    "\n",
    "\n",
    "## Here we print the last version of the data set\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155070",
   "metadata": {},
   "source": [
    "## Feature Engineering test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9cbb207",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## Distance ##\n",
    "##############\n",
    "\n",
    "\n",
    "## Here assign to n the amount of observations we have in the dataset\n",
    "n = test_data.shape[0]\n",
    "\n",
    "## Creating empty list to store the reuslts\n",
    "distance_to_append = []\n",
    "\n",
    "## Looping through each row an computing the distance between transaction address and merchants address\n",
    "for i in range(0,n):\n",
    "\n",
    "    ## Here we gather the lat and long from the transaciton address\n",
    "    coords_1 = (test_data['lat'][i], test_data['long'][i])\n",
    "\n",
    "    ## Here we gather the lat and long from the merchants address\n",
    "    coords_2 = (test_data['merch_lat'][i], test_data['merch_long'][i])\n",
    "\n",
    "    ## Here we compute the disance in miles between the locations\n",
    "    distance_to_append.append(geopy.distance.geodesic(coords_1, coords_2).miles)\n",
    "\n",
    "## Adding results to our data set\n",
    "test_data['distance'] = distance_to_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bec9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## AVG Distance ##\n",
    "##################\n",
    "\n",
    "## Here we create a groupby function to get the mean distance by each category\n",
    "avg_dist_by_category = pd.DataFrame(test_data.groupby(['cc_num','category'])['distance'].mean())\n",
    "\n",
    "## Here we create a temporary column holding our index values (cc_num)\n",
    "avg_dist_by_category['columns'] = avg_dist_by_category.index\n",
    "\n",
    "## Here we drop our temporary column and reset our index, which was previously our cc_num\n",
    "avg_dist_by_category = avg_dist_by_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns of the groupby function\n",
    "avg_dist_by_category.columns = ['cc_num','category','avg_distance_by_category']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "test_data = avg_dist_by_category.merge(test_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ee3ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## AVG Distance by Category##\n",
    "#############################\n",
    "\n",
    "## Here we create a groupby function to get the mean distance by each category\n",
    "avg_dist = pd.DataFrame(test_data.groupby(['cc_num'])['distance'].mean())\n",
    "\n",
    "## Here we create a temporary column holding our index values (cc_num)\n",
    "avg_dist['columns'] = avg_dist.index\n",
    "\n",
    "## Here we drop our temporary column and reset our index, which was previously our cc_num\n",
    "avg_dist = avg_dist.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns of the groupby function\n",
    "avg_dist.columns = ['cc_num','avg_distance']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "test_data = avg_dist.merge(test_data, on = ['cc_num'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e5e8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "## Age ##\n",
    "#########\n",
    "\n",
    "## Creating empty list to store the resutls\n",
    "ages_to_append = []\n",
    "\n",
    "## Looping through each observation and computing the age of each individual from its DOB\n",
    "for i in range(0,n):\n",
    "\n",
    "    ## Here we add the last date of this year\n",
    "    year_of_2021 = datetime.strptime('2021-12-31', \"%Y-%m-%d\")\n",
    "\n",
    "    ## Here we call each DOB in the dataset\n",
    "    dob = datetime.strptime(test_data.dob[i], \"%Y-%m-%d\")\n",
    "\n",
    "    ## Here we compute the ages\n",
    "    ages_to_append.append(relativedelta(year_of_2021, dob).years)\n",
    "\n",
    "## Adding results to our data set\n",
    "test_data['age'] = ages_to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4570a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## Days of the Week ##\n",
    "######################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "dates = pd.to_datetime(test_data['trans_date_trans_time'])\n",
    "\n",
    "## Here we use our library to get the day of the week based on the transformed column\n",
    "test_data['day_of_week'] = dates.dt.day_name()\n",
    "\n",
    "##################\n",
    "## Uses per day ##\n",
    "##################\n",
    "\n",
    "## Here we create a dataframe containing the uses by day per card\n",
    "uses_per_day = pd.DataFrame(test_data.groupby('cc_num')['day_of_week'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_day['columns'] = uses_per_day.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_day.columns = ['uses_per_day','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_day = uses_per_day.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = uses_per_day.merge(test_data, on = ['cc_num','day_of_week'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8b41055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## Month of the year ##\n",
    "#######################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "months = pd.to_datetime(test_data['trans_date_trans_time'])\n",
    "\n",
    "## Here we use our library to get the month of the year based on the transformed column\n",
    "test_data['month'] = dates.dt.month\n",
    "\n",
    "####################\n",
    "## Uses per month ##\n",
    "####################\n",
    "\n",
    "## Here we create a dataframe containing the card uses by month\n",
    "uses_per_month = pd.DataFrame(test_data.groupby('cc_num')['month'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_month['columns'] = uses_per_month.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_month.columns = ['uses_per_month','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_month = uses_per_month.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = uses_per_month.merge(test_data, on = ['cc_num','month'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91ae1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Hour of the day ##\n",
    "#####################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "hour_of_the_day = []\n",
    "\n",
    "## Here we loop throough each observation, change the format of the items in each column, \n",
    "## and retrieve the hour of the day\n",
    "for i in range(0,n):\n",
    "    hour_of_the_day.append(datetime.strptime(test_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\").hour)\n",
    "\n",
    "## Here we attribute our results to a column\n",
    "test_data['hour_of_the_day'] = hour_of_the_day\n",
    "\n",
    "###################\n",
    "## Uses per hour ##\n",
    "###################\n",
    "\n",
    "## Here we create a dataframe containing the card uses by hour of day\n",
    "uses_per_hour = pd.DataFrame(test_data.groupby('cc_num')['hour_of_the_day'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_hour['columns'] = uses_per_hour.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_hour.columns = ['uses_per_hour','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_hour = uses_per_hour.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = uses_per_hour.merge(test_data, on = ['cc_num','hour_of_the_day'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e52754fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## Total card uses by customer ##\n",
    "#################################\n",
    "\n",
    "## Here we get the number of transactions shown in the data set per card\n",
    "Uses = pd.DataFrame(test_data['cc_num'].value_counts())\n",
    "\n",
    "## Here we create a column to keep our cc_num\n",
    "Uses['cc_number2'] = Uses.index\n",
    "\n",
    "## Here we reset our index\n",
    "Uses = Uses.reset_index(drop = True)\n",
    "\n",
    "## Here we rename our columns\n",
    "Uses.columns = ['total_uses','cc_num']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "test_data = Uses.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3659c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Total card uses by customer grouping ##\n",
    "##########################################\n",
    "\n",
    "conditions = [\n",
    "    (test_data['total_uses'] < 400),\n",
    "    (test_data['total_uses'] > 400) & (test_data['total_uses'] < 900),\n",
    "    (test_data['total_uses'] > 900) & (test_data['total_uses'] < 1200),\n",
    "    (test_data['total_uses'] > 1200) & (test_data['total_uses'] < 1800),\n",
    "    (test_data['total_uses'] > 1800) & (test_data['total_uses'] < 2200),\n",
    "    (test_data['total_uses'] > 2200) & (test_data['total_uses'] < 2800),\n",
    "    (test_data['total_uses'] > 2800) & (test_data['total_uses'] < 3200)\n",
    "    ]\n",
    "\n",
    "    \n",
    "classes = [\n",
    "    'LESS THAN 400',\n",
    "    'BETWEEN 400 AND 900',\n",
    "    'BETWEEN 900 AND 1200',\n",
    "    'BETWEEN 1200 AND 1800',\n",
    "    'BETWEEN 1800 AND 2200',\n",
    "    'BETWEEN 2200 AND 2800',\n",
    "    'BETWEEN 2800 AND 3200'\n",
    "    ]\n",
    "test_data['transactions_group'] = np.select(conditions,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "731a05f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BETWEEN 400 AND 900      334337\n",
       "BETWEEN 900 AND 1200      97679\n",
       "BETWEEN 1200 AND 1800     70272\n",
       "LESS THAN 400             49831\n",
       "0                          3600\n",
       "Name: transactions_group, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.transactions_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b1c63bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BETWEEN 1200 AND 1800    318104\n",
       "BETWEEN 1800 AND 2200    311240\n",
       "BETWEEN 900 AND 1200     209534\n",
       "BETWEEN 2200 AND 2800    181592\n",
       "BETWEEN 2800 AND 3200    161709\n",
       "BETWEEN 400 AND 900      113755\n",
       "LESS THAN 400               741\n",
       "Name: transactions_group, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.transactions_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96393ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Difference in minutes between each transaction ##\n",
    "####################################################\n",
    "\n",
    "## Here we create a list to hold our results\n",
    "new_time = []\n",
    "n = test_data.shape[0]\n",
    "## Here we loop through each observation and transform the format of our data\n",
    "for i in range(0,n):\n",
    "    new_time.append(datetime.strptime(test_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "## Here we create a column containing transformed data to compute the difference in minutes\n",
    "## New format was recquired for the library to work\n",
    "test_data['transformed_time'] = new_time\n",
    "\n",
    "test_data = test_data.sort_values(by = 'transformed_time', ascending = True)\n",
    "\n",
    "## Here we compute the difference in minutes between each transacion\n",
    "test_data['diff_by_card_trans'] = test_data.groupby('cc_num')\\\n",
    "                              ['transformed_time'].diff().apply(lambda x: \\\n",
    "                              x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "347bb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## AVG payment by category ##\n",
    "#############################\n",
    "\n",
    "## Here we create a dataframe containing the avg amount per category\n",
    "amt_per_category = pd.DataFrame(test_data.groupby(['cc_num','category'])['amt'].mean())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_per_category['columns'] = amt_per_category.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_per_category = amt_per_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_per_category.columns = ['cc_num','category','avg_by_category']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = amt_per_category.merge(test_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a25ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## AVG amount spent per card ##\n",
    "###############################\n",
    "\n",
    "## Here we create a dataframe containing the avg amount spent per card\n",
    "avg_amt = pd.DataFrame(test_data.groupby('cc_num')['amt'].mean())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "avg_amt['columns'] = avg_amt.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "avg_amt = avg_amt.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "avg_amt.columns = ['cc_num', 'avg_amt']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = avg_amt.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a65c4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "## First and last purchase of each credit card ##\n",
    "#################################################\n",
    "\n",
    "## Here we extract the first and last transaction time recorded for each credit card\n",
    "temp_cc_time_max = pd.DataFrame(test_data.groupby('cc_num')['trans_date_trans_time'].max())\n",
    "temp_cc_time_min = pd.DataFrame(test_data.groupby('cc_num')['trans_date_trans_time'].min())\n",
    "\n",
    "## Here we assign the index(cc_num) to a column\n",
    "temp_cc_time_max['columns'] = temp_cc_time_max.index\n",
    "temp_cc_time_min['columns'] = temp_cc_time_min.index\n",
    "\n",
    "## Here we reset the index\n",
    "temp_cc_time_max = temp_cc_time_max.reset_index().drop(columns = 'columns')\n",
    "temp_cc_time_min = temp_cc_time_min.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "temp_cc_time_max.columns = ['cc_num','max_date']\n",
    "temp_cc_time_min.columns = ['cc_num','min_date']\n",
    "\n",
    "## Here we merge the new columns to our original data\n",
    "test_data = temp_cc_time_max.merge(test_data, on = 'cc_num', how = 'left')\n",
    "test_data = temp_cc_time_min.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fd4d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "## Diffefence in time between first and last purchase for each credit card ##\n",
    "#############################################################################\n",
    "\n",
    "## Here we transform the date type for each column\n",
    "min_dates = pd.to_datetime(test_data.min_date) \n",
    "max_dates = pd.to_datetime(test_data.max_date)\n",
    "\n",
    "## Here we compute the diff in minutes between first and last purchase\n",
    "diff_in_time = max_dates - min_dates\n",
    "\n",
    "## Here we create a dataframe with our results\n",
    "temp_data = pd.DataFrame(diff_in_time)\n",
    "\n",
    "## Here we add our results to a column in our data\n",
    "test_data['diff_first_last'] = temp_data.apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1d17df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## STD amount per card ##\n",
    "#########################\n",
    "\n",
    "## Here we create a dataframe containing the std from amount spent per card\n",
    "amt_std = pd.DataFrame(test_data.groupby('cc_num')['amt'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'std_amt']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = amt_std.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0835c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "## STD amount per card by category ##\n",
    "#####################################\n",
    "\n",
    "## Here we create a dataframe containing the std from amount spent per card by category\n",
    "amt_std = pd.DataFrame(test_data.groupby(['cc_num','category'])['amt'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'category','std_amt_by_category']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = amt_std.merge(test_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "550dc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## STD distance per card by category ##\n",
    "#######################################\n",
    "\n",
    "## Here we create a dataframe containing the std distance per card by category\n",
    "amt_std = pd.DataFrame(test_data.groupby(['cc_num','category'])['distance'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'category','std_dist_by_category']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = amt_std.merge(test_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4bfffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## STD distance per card ##\n",
    "###########################\n",
    "\n",
    "## Here we create a dataframe containing the std distance per card by category\n",
    "amt_std = pd.DataFrame(test_data.groupby('cc_num')['distance'].std())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "amt_std['columns'] = amt_std.index\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "amt_std = amt_std.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns\n",
    "amt_std.columns = ['cc_num', 'std_dist']\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = amt_std.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d2b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Purhase amt and dist > avg and > (1,2) std ##\n",
    "################################################\n",
    "\n",
    "## Here we create a binary column containing 0 if amount spent is less than avg amount\n",
    "test_data['purchase_>_avg'] = np.where(test_data['amt'] > test_data['avg_amt'],1,0)\n",
    "\n",
    "## Here we create a binary column containing 0 if amount spent is less than avg amount per category\n",
    "test_data['purchase_>_avg_by_category'] = np.where(test_data['amt'] > test_data['avg_by_category'],1,0)\n",
    "\n",
    "## Here we create a binary column containing 0 if distance is less than avg distance\n",
    "test_data['purchase_>_distance'] = np.where(test_data['distance'] > test_data['avg_distance'],1,0)\n",
    "\n",
    "## Here we create a binary column containing 0 if distance is less than avg distance by category\n",
    "test_data['purchase_>_distance_by_category'] = np.where(test_data['distance'] > test_data['avg_distance_by_category'],1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the amount spent is higher than 1 std\n",
    "test_data['amt_>_1_std'] = np.where(test_data.amt > (test_data.avg_amt + test_data.std_amt),1,0)\n",
    "## Here we classify if the amount spent is higher than 2 std\n",
    "test_data['amt_>_2_std'] = np.where(test_data.amt > (test_data.avg_amt + 2*test_data.std_amt),1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the amount spent by category is higher than 1 std\n",
    "test_data['amt_>_1_std_by_cagegory'] = np.where(test_data.amt > (test_data.avg_by_category + test_data.std_amt_by_category),1,0)\n",
    "## Here we classify if the amount spent by category is higher than 2 std\n",
    "test_data['amt_>_2_std_by_cagegory'] = np.where(test_data.amt > (test_data.avg_by_category + 2*test_data.std_amt_by_category),1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the distance is higher than 1 std\n",
    "test_data['dist_>_1_std'] = np.where(test_data.distance > (test_data.avg_distance + test_data.std_dist),1,0)\n",
    "## Here we classify if the distance is higher than 2 std\n",
    "test_data['dist_>_2_std'] = np.where(test_data.distance > (test_data.avg_distance + 2*test_data.std_dist),1,0)\n",
    "\n",
    "\n",
    "## Here we classify if the distance by category is higher than 1 std\n",
    "test_data['dist_>_1_std_by_cagegory'] = np.where(test_data.distance > (test_data.avg_distance_by_category + test_data.std_dist_by_category),1,0)\n",
    "## Here we classify if the dintance by category is higher than 2 std\n",
    "test_data['dist_>_2_std_by_cagegory'] = np.where(test_data.distance > (test_data.avg_distance_by_category + 2*test_data.std_dist_by_category),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d7c020d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>category</th>\n",
       "      <th>uses_per_category</th>\n",
       "      <th>std_dist</th>\n",
       "      <th>std_dist_by_category</th>\n",
       "      <th>std_amt_by_category</th>\n",
       "      <th>std_amt</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>avg_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>purchase_&gt;_distance</th>\n",
       "      <th>purchase_&gt;_distance_by_category</th>\n",
       "      <th>amt_&gt;_1_std</th>\n",
       "      <th>amt_&gt;_2_std</th>\n",
       "      <th>amt_&gt;_1_std_by_cagegory</th>\n",
       "      <th>amt_&gt;_2_std_by_cagegory</th>\n",
       "      <th>dist_&gt;_1_std</th>\n",
       "      <th>dist_&gt;_2_std</th>\n",
       "      <th>dist_&gt;_1_std_by_cagegory</th>\n",
       "      <th>dist_&gt;_2_std_by_cagegory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>92</td>\n",
       "      <td>18.1254</td>\n",
       "      <td>18.822547</td>\n",
       "      <td>17.625537</td>\n",
       "      <td>180.015519</td>\n",
       "      <td>2020-06-21 13:05:42</td>\n",
       "      <td>2020-12-31 05:16:50</td>\n",
       "      <td>66.499484</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>92</td>\n",
       "      <td>18.1254</td>\n",
       "      <td>18.822547</td>\n",
       "      <td>17.625537</td>\n",
       "      <td>180.015519</td>\n",
       "      <td>2020-06-21 13:05:42</td>\n",
       "      <td>2020-12-31 05:16:50</td>\n",
       "      <td>66.499484</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>92</td>\n",
       "      <td>18.1254</td>\n",
       "      <td>18.822547</td>\n",
       "      <td>17.625537</td>\n",
       "      <td>180.015519</td>\n",
       "      <td>2020-06-21 13:05:42</td>\n",
       "      <td>2020-12-31 05:16:50</td>\n",
       "      <td>66.499484</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>92</td>\n",
       "      <td>18.1254</td>\n",
       "      <td>18.822547</td>\n",
       "      <td>17.625537</td>\n",
       "      <td>180.015519</td>\n",
       "      <td>2020-06-21 13:05:42</td>\n",
       "      <td>2020-12-31 05:16:50</td>\n",
       "      <td>66.499484</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60416207185</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>92</td>\n",
       "      <td>18.1254</td>\n",
       "      <td>18.822547</td>\n",
       "      <td>17.625537</td>\n",
       "      <td>180.015519</td>\n",
       "      <td>2020-06-21 13:05:42</td>\n",
       "      <td>2020-12-31 05:16:50</td>\n",
       "      <td>66.499484</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cc_num       category  uses_per_category  std_dist  \\\n",
       "0  60416207185  gas_transport                 92   18.1254   \n",
       "1  60416207185  gas_transport                 92   18.1254   \n",
       "2  60416207185  gas_transport                 92   18.1254   \n",
       "3  60416207185  gas_transport                 92   18.1254   \n",
       "4  60416207185  gas_transport                 92   18.1254   \n",
       "\n",
       "   std_dist_by_category  std_amt_by_category     std_amt             min_date  \\\n",
       "0             18.822547            17.625537  180.015519  2020-06-21 13:05:42   \n",
       "1             18.822547            17.625537  180.015519  2020-06-21 13:05:42   \n",
       "2             18.822547            17.625537  180.015519  2020-06-21 13:05:42   \n",
       "3             18.822547            17.625537  180.015519  2020-06-21 13:05:42   \n",
       "4             18.822547            17.625537  180.015519  2020-06-21 13:05:42   \n",
       "\n",
       "              max_date    avg_amt  ...  purchase_>_distance  \\\n",
       "0  2020-12-31 05:16:50  66.499484  ...                    1   \n",
       "1  2020-12-31 05:16:50  66.499484  ...                    1   \n",
       "2  2020-12-31 05:16:50  66.499484  ...                    1   \n",
       "3  2020-12-31 05:16:50  66.499484  ...                    0   \n",
       "4  2020-12-31 05:16:50  66.499484  ...                    0   \n",
       "\n",
       "   purchase_>_distance_by_category  amt_>_1_std  amt_>_2_std  \\\n",
       "0                                1            0            0   \n",
       "1                                1            0            0   \n",
       "2                                1            0            0   \n",
       "3                                0            0            0   \n",
       "4                                0            0            0   \n",
       "\n",
       "   amt_>_1_std_by_cagegory  amt_>_2_std_by_cagegory dist_>_1_std  \\\n",
       "0                        0                        0            1   \n",
       "1                        0                        0            1   \n",
       "2                        0                        0            0   \n",
       "3                        0                        0            0   \n",
       "4                        1                        1            0   \n",
       "\n",
       "   dist_>_2_std  dist_>_1_std_by_cagegory  dist_>_2_std_by_cagegory  \n",
       "0             0                         1                         0  \n",
       "1             0                         1                         0  \n",
       "2             0                         0                         0  \n",
       "3             0                         0                         0  \n",
       "4             0                         0                         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "## Uses per category ##\n",
    "#######################\n",
    "\n",
    "## Here we create a dataframe containing the uses by category per card\n",
    "uses_per_category = pd.DataFrame(test_data.groupby('cc_num')['category'].value_counts())\n",
    "\n",
    "## Here we assign a column containing the index of the dataframe (which is the cc_num)\n",
    "uses_per_category['columns'] = uses_per_category.index\n",
    "\n",
    "## Here we rename the columns\n",
    "uses_per_category.columns = ['uses_per_category','columns']\n",
    "\n",
    "## Here we reset index to get 0, 1, 2 instead of the cc_nums \n",
    "uses_per_category = uses_per_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we merge the new data to our table\n",
    "test_data = uses_per_category.merge(test_data, on = ['cc_num','category'], how = 'left')\n",
    "\n",
    "\n",
    "## Here we print the last version of the data set\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0723ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we export the file containing all of the new feature to a csv file. \n",
    "train_data.to_csv (\"/Users/gabrielmedeiros/Documents/OneDrive/Business analytics/DATA_445_Machine_Learning/CleanTrainData.csv\", index = None, header=True)\n",
    "test_data.to_csv (\"/Users/gabrielmedeiros/Documents/OneDrive/Business analytics/DATA_445_Machine_Learning/CleanTestData.csv\", index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
