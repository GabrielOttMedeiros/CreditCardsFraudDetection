{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daf3619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['uses_per_category', 'std_dist', 'std_dist_by_category',\n",
       "       'std_amt_by_category', 'std_amt', 'avg_amt', 'avg_by_category',\n",
       "       'total_uses', 'hour_of_the_day', 'uses_per_hour', 'month',\n",
       "       'uses_per_month', 'uses_per_day', 'avg_distance',\n",
       "       'avg_distance_by_category', 'amt', 'zip', 'lat', 'long', 'city_pop',\n",
       "       'unix_time', 'merch_lat', 'merch_long', 'distance', 'age',\n",
       "       'diff_by_card_trans', 'diff_first_last', 'purchase_>_avg',\n",
       "       'purchase_>_avg_by_category', 'purchase_>_distance',\n",
       "       'purchase_>_distance_by_category', 'amt_>_1_std', 'amt_>_2_std',\n",
       "       'amt_>_1_std_by_cagegory', 'amt_>_2_std_by_cagegory', 'dist_>_1_std',\n",
       "       'dist_>_2_std', 'dist_>_1_std_by_cagegory', 'dist_>_2_std_by_cagegory'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import EvaluateModels as em\n",
    "import boto3\n",
    "\n",
    "## defining bucket\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = 'gabriel-de-medeiros'\n",
    "\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## specifying file from the bucket\n",
    "file_key = 'CleanTrainData.csv'\n",
    "file_key2 = 'CleanTestData.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "\n",
    "## Reading csv file, index_col = 0 makes the first column of the data to become the index of our pandas data frame\n",
    "train_data = pd.read_csv(file_content_stream, index_col = 0)\n",
    "test_data = pd.read_csv(file_content_stream2, index_col = 0)\n",
    "\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\n",
    "train_data = train_data.select_dtypes(exclude=['object'])\n",
    "test_data = test_data.select_dtypes(exclude=['object'])\n",
    "\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# train_data = train_data.iloc[0:100000,:]\n",
    "# test_data = test_data.iloc[0:100,:]\n",
    "\n",
    "\n",
    "X_train, Y_train = train_data.drop(columns = 'is_fraud'), train_data['is_fraud']\n",
    "\n",
    "\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "import Get_Variable_Importance as gvi\n",
    "\n",
    "print('DecisionTrees')\n",
    "decision_trees_variable_importance = gvi.Decision_Tree_Importance(X,Y)\n",
    "\n",
    "print('RandomForest')\n",
    "random_forest_variable_importance = gvi.Random_Forest_Importance(X,Y)\n",
    "\n",
    "print('ImportantVariables')\n",
    "df_importance_columns = gvi.Getting_Best_Model(decision_trees_variable_importance,random_forest_variable_importance,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b36ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31651679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:03<00:00,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "## Decision Trees\n",
    "DTC_results = em.DecisionTreesResults(X_test, X_train, Y_test, Y_train)\n",
    "DTC_best_model = em.DecisionTreesBestModel(DTC_results)\n",
    "\n",
    "# ## Random Forest\n",
    "# RF_results = em.RandomForestResults(X_test, X_train, Y_test, Y_train)\n",
    "# RF_best_model = em.DecisionTreesBestModel(RF_results)\n",
    "\n",
    "## Neural Networks\n",
    "#NN_results = em.NeuralNetworksResults(X_test, X_train, Y_test, Y_train)\n",
    "\n",
    "# ## SVC\n",
    "# SVC_results = em.SupportVectorMachineResults(X_test, X_train, Y_test, Y_train)\n",
    "# SVC_best_model = em.SvcBestModel(SVC_results)\n",
    "\n",
    "# ## Logistic Regression\n",
    "# LR_results = em.LogisticRegressionResults(X_test, X_train, Y_test, Y_train)\n",
    "\n",
    "# ## AdaBoost Decision Trees\n",
    "# ADA_DTC = em.AdaBoostDecisionTreesResults(X_test, X_train, Y_test, Y_train, DTC_best_model)\n",
    "\n",
    "# ## AdaBoost SVC\n",
    "# ADA_SVC= em.AdaBoostSvmResults(X_test, X_train, Y_test, Y_train, SVC_best_model)\n",
    "\n",
    "## GradientBoosting\n",
    "# GBC_results = em.GradientBoostingResults(X_test, X_train, Y_test, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "# DTC_results.to_csv('CreditCardsFraudDetection/Algorithm/DTC_results.csv', index = False)\n",
    "# DTC_best_model.to_csv('CreditCardsFraudDetection/Algorithm/DTC_best_model.csv', index = False)\n",
    "# RF_results.to_csv('CreditCardsFraudDetection/Algorithm/RF_results.csv', index = False)\n",
    "# RF_best_model.to_csv('CreditCardsFraudDetection/Algorithm/RF_best_model.csv', index = False)\n",
    "# NN_results.to_csv('CreditCardsFraudDetection/Algorithm/NN_results.csv', index = False)\n",
    "# SVC_results.to_csv('CreditCardsFraudDetection/Algorithm/SVC_results.csv', index = False)\n",
    "# SVC_best_model.to_csv('CreditCardsFraudDetection/Algorithm/SVC_best_model.csv', index = False)\n",
    "# LR_results.to_csv('CreditCardsFraudDetection/Algorithm/LR_results.csv', index = False)\n",
    "# ADA_DTC.to_csv('CreditCardsFraudDetection/Algorithm/ADA_DTC.csv', index = False)\n",
    "# ADA_SVC.to_csv('CreditCardsFraudDetection/Algorithm/ADA_SVC.csv', index = False)\n",
    "# GBC_results.to_csv('CreditCardsFraudDetection/Algorithm/GBC_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af6ebce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>cut_off</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.99197</td>\n",
       "      <td>0.702471</td>\n",
       "      <td>0.847221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  cut_off  accuracy    recall  Performance\n",
       "40        7.0      0.1   0.99197  0.702471     0.847221"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14f0338d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>cut_off</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.572719</td>\n",
       "      <td>0.743418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.982349</td>\n",
       "      <td>0.465779</td>\n",
       "      <td>0.724064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.463403</td>\n",
       "      <td>0.729145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.463403</td>\n",
       "      <td>0.729145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.463403</td>\n",
       "      <td>0.729145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.498406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.463403</td>\n",
       "      <td>0.729145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.915991</td>\n",
       "      <td>0.435361</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.854087</td>\n",
       "      <td>0.430664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.915991</td>\n",
       "      <td>0.435361</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.991920</td>\n",
       "      <td>0.499083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.913441</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>0.805580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.991920</td>\n",
       "      <td>0.499083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.991920</td>\n",
       "      <td>0.499083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.983229</td>\n",
       "      <td>0.466255</td>\n",
       "      <td>0.724742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.914999</td>\n",
       "      <td>0.573194</td>\n",
       "      <td>0.744097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.914999</td>\n",
       "      <td>0.573194</td>\n",
       "      <td>0.744097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.914999</td>\n",
       "      <td>0.573194</td>\n",
       "      <td>0.744097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.914992</td>\n",
       "      <td>0.571293</td>\n",
       "      <td>0.743142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.984186</td>\n",
       "      <td>0.327471</td>\n",
       "      <td>0.655829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.499294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.993735</td>\n",
       "      <td>0.658745</td>\n",
       "      <td>0.826240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.995553</td>\n",
       "      <td>0.590304</td>\n",
       "      <td>0.792929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.995553</td>\n",
       "      <td>0.590304</td>\n",
       "      <td>0.792929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.995553</td>\n",
       "      <td>0.590304</td>\n",
       "      <td>0.792929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.995553</td>\n",
       "      <td>0.590304</td>\n",
       "      <td>0.792929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.983024</td>\n",
       "      <td>0.591255</td>\n",
       "      <td>0.787139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.915575</td>\n",
       "      <td>0.598384</td>\n",
       "      <td>0.756980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>0.925856</td>\n",
       "      <td>0.466450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.996564</td>\n",
       "      <td>0.397814</td>\n",
       "      <td>0.697189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.992326</td>\n",
       "      <td>0.692966</td>\n",
       "      <td>0.842646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.981267</td>\n",
       "      <td>0.659221</td>\n",
       "      <td>0.820244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.913300</td>\n",
       "      <td>0.705798</td>\n",
       "      <td>0.809549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.991920</td>\n",
       "      <td>0.499066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.913300</td>\n",
       "      <td>0.705798</td>\n",
       "      <td>0.809549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.915818</td>\n",
       "      <td>0.607890</td>\n",
       "      <td>0.761854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.984168</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>0.757769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.984168</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>0.757769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.941540</td>\n",
       "      <td>0.474310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.984168</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>0.757769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.991970</td>\n",
       "      <td>0.702471</td>\n",
       "      <td>0.847221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.980225</td>\n",
       "      <td>0.688213</td>\n",
       "      <td>0.834219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.993762</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.822214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.706274</td>\n",
       "      <td>0.809658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>0.482953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>0.614544</td>\n",
       "      <td>0.804857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.995143</td>\n",
       "      <td>0.613593</td>\n",
       "      <td>0.804368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.996356</td>\n",
       "      <td>0.548004</td>\n",
       "      <td>0.772180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.996381</td>\n",
       "      <td>0.548004</td>\n",
       "      <td>0.772192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.984276</td>\n",
       "      <td>0.514259</td>\n",
       "      <td>0.749267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.911790</td>\n",
       "      <td>0.744297</td>\n",
       "      <td>0.828044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.911988</td>\n",
       "      <td>0.741920</td>\n",
       "      <td>0.826954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.981652</td>\n",
       "      <td>0.664449</td>\n",
       "      <td>0.823050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.660646</td>\n",
       "      <td>0.827421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.982890</td>\n",
       "      <td>0.494605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.995450</td>\n",
       "      <td>0.623099</td>\n",
       "      <td>0.809275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.983722</td>\n",
       "      <td>0.595057</td>\n",
       "      <td>0.789389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.915582</td>\n",
       "      <td>0.624525</td>\n",
       "      <td>0.770054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.931084</td>\n",
       "      <td>0.469179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.930608</td>\n",
       "      <td>0.468937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.978668</td>\n",
       "      <td>0.706749</td>\n",
       "      <td>0.842709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.983840</td>\n",
       "      <td>0.495024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.485046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.914020</td>\n",
       "      <td>0.709125</td>\n",
       "      <td>0.811573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.947719</td>\n",
       "      <td>0.477339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.915035</td>\n",
       "      <td>0.679658</td>\n",
       "      <td>0.797347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.995701</td>\n",
       "      <td>0.623574</td>\n",
       "      <td>0.809637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.983225</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>0.802924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.946293</td>\n",
       "      <td>0.476712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.983488</td>\n",
       "      <td>0.601711</td>\n",
       "      <td>0.792599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.979532</td>\n",
       "      <td>0.700095</td>\n",
       "      <td>0.839814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.993242</td>\n",
       "      <td>0.687738</td>\n",
       "      <td>0.840490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>0.484079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.914799</td>\n",
       "      <td>0.695342</td>\n",
       "      <td>0.805071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.915098</td>\n",
       "      <td>0.673954</td>\n",
       "      <td>0.794526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.982766</td>\n",
       "      <td>0.592205</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.944392</td>\n",
       "      <td>0.475693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>0.792693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.936787</td>\n",
       "      <td>0.471929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.572719</td>\n",
       "      <td>0.778034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  cut_off  accuracy    recall  Performance\n",
       "0         3.0     0.10  0.914117  0.572719     0.743418\n",
       "1         3.0     0.15  0.982349  0.465779     0.724064\n",
       "2         3.0     0.20  0.994887  0.463403     0.729145\n",
       "3         3.0     0.25  0.994887  0.463403     0.729145\n",
       "4         3.0     0.30  0.994887  0.463403     0.729145\n",
       "5         3.0     0.35  0.005367  0.991445     0.498406\n",
       "6         3.0     0.40  0.994887  0.463403     0.729145\n",
       "7         3.0     0.45  0.915991  0.435361     0.675676\n",
       "8         3.0     0.50  0.007240  0.854087     0.430664\n",
       "9         3.0     0.55  0.915991  0.435361     0.675676\n",
       "10        4.0     0.10  0.006247  0.991920     0.499083\n",
       "11        4.0     0.15  0.913441  0.697719     0.805580\n",
       "12        4.0     0.20  0.006247  0.991920     0.499083\n",
       "13        4.0     0.25  0.006247  0.991920     0.499083\n",
       "14        4.0     0.30  0.983229  0.466255     0.724742\n",
       "15        4.0     0.35  0.914999  0.573194     0.744097\n",
       "16        4.0     0.40  0.914999  0.573194     0.744097\n",
       "17        4.0     0.45  0.914999  0.573194     0.744097\n",
       "18        4.0     0.50  0.914992  0.571293     0.743142\n",
       "19        4.0     0.55  0.984186  0.327471     0.655829\n",
       "20        5.0     0.10  0.006193  0.992395     0.499294\n",
       "21        5.0     0.15  0.993735  0.658745     0.826240\n",
       "22        5.0     0.20  0.995553  0.590304     0.792929\n",
       "23        5.0     0.25  0.995553  0.590304     0.792929\n",
       "24        5.0     0.30  0.995553  0.590304     0.792929\n",
       "25        5.0     0.35  0.995553  0.590304     0.792929\n",
       "26        5.0     0.40  0.983024  0.591255     0.787139\n",
       "27        5.0     0.45  0.915575  0.598384     0.756980\n",
       "28        5.0     0.50  0.007044  0.925856     0.466450\n",
       "29        5.0     0.55  0.996564  0.397814     0.697189\n",
       "30        6.0     0.10  0.992326  0.692966     0.842646\n",
       "31        6.0     0.15  0.981267  0.659221     0.820244\n",
       "32        6.0     0.20  0.913300  0.705798     0.809549\n",
       "33        6.0     0.25  0.006212  0.991920     0.499066\n",
       "34        6.0     0.30  0.913300  0.705798     0.809549\n",
       "35        6.0     0.35  0.915818  0.607890     0.761854\n",
       "36        6.0     0.40  0.984168  0.531369     0.757769\n",
       "37        6.0     0.45  0.984168  0.531369     0.757769\n",
       "38        6.0     0.50  0.007080  0.941540     0.474310\n",
       "39        6.0     0.55  0.984168  0.531369     0.757769\n",
       "40        7.0     0.10  0.991970  0.702471     0.847221\n",
       "41        7.0     0.15  0.980225  0.688213     0.834219\n",
       "42        7.0     0.20  0.993762  0.650665     0.822214\n",
       "43        7.0     0.25  0.913043  0.706274     0.809658\n",
       "44        7.0     0.30  0.006781  0.959125     0.482953\n",
       "45        7.0     0.35  0.995170  0.614544     0.804857\n",
       "46        7.0     0.40  0.995143  0.613593     0.804368\n",
       "47        7.0     0.45  0.996356  0.548004     0.772180\n",
       "48        7.0     0.50  0.996381  0.548004     0.772192\n",
       "49        7.0     0.55  0.984276  0.514259     0.749267\n",
       "50        8.0     0.10  0.911790  0.744297     0.828044\n",
       "51        8.0     0.15  0.911988  0.741920     0.826954\n",
       "52        8.0     0.20  0.981652  0.664449     0.823050\n",
       "53        8.0     0.25  0.994196  0.660646     0.827421\n",
       "54        8.0     0.30  0.006320  0.982890     0.494605\n",
       "55        8.0     0.35  0.995450  0.623099     0.809275\n",
       "56        8.0     0.40  0.983722  0.595057     0.789389\n",
       "57        8.0     0.45  0.915582  0.624525     0.770054\n",
       "58        8.0     0.50  0.007274  0.931084     0.469179\n",
       "59        8.0     0.55  0.007265  0.930608     0.468937\n",
       "60        9.0     0.10  0.978668  0.706749     0.842709\n",
       "61        9.0     0.15  0.006207  0.983840     0.495024\n",
       "62        9.0     0.20  0.006689  0.963403     0.485046\n",
       "63        9.0     0.25  0.914020  0.709125     0.811573\n",
       "64        9.0     0.30  0.006959  0.947719     0.477339\n",
       "65        9.0     0.35  0.915035  0.679658     0.797347\n",
       "66        9.0     0.40  0.995701  0.623574     0.809637\n",
       "67        9.0     0.45  0.983225  0.622624     0.802924\n",
       "68        9.0     0.50  0.007132  0.946293     0.476712\n",
       "69        9.0     0.55  0.983488  0.601711     0.792599\n",
       "70       10.0     0.10  0.979532  0.700095     0.839814\n",
       "71       10.0     0.15  0.993242  0.687738     0.840490\n",
       "72       10.0     0.20  0.006655  0.961502     0.484079\n",
       "73       10.0     0.25  0.914799  0.695342     0.805071\n",
       "74       10.0     0.30  0.915098  0.673954     0.794526\n",
       "75       10.0     0.35  0.982766  0.592205     0.787486\n",
       "76       10.0     0.40  0.006994  0.944392     0.475693\n",
       "77       10.0     0.45  0.915233  0.670152     0.792693\n",
       "78       10.0     0.50  0.007071  0.936787     0.471929\n",
       "79       10.0     0.55  0.983349  0.572719     0.778034"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "DTC_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d01b73e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:26<00:00, 14.69s/it]\n"
     ]
    }
   ],
   "source": [
    "LR_results = em.LogisticRegressionResults(X_test, X_train, Y_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3a6aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_off</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.299337</td>\n",
       "      <td>0.927757</td>\n",
       "      <td>0.613547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.797842</td>\n",
       "      <td>0.803232</td>\n",
       "      <td>0.800537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.967645</td>\n",
       "      <td>0.695342</td>\n",
       "      <td>0.831494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.983812</td>\n",
       "      <td>0.606464</td>\n",
       "      <td>0.795138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.987798</td>\n",
       "      <td>0.517586</td>\n",
       "      <td>0.752692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.990638</td>\n",
       "      <td>0.483840</td>\n",
       "      <td>0.737239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.992778</td>\n",
       "      <td>0.468631</td>\n",
       "      <td>0.730705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>0.438213</td>\n",
       "      <td>0.716053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.994450</td>\n",
       "      <td>0.392586</td>\n",
       "      <td>0.693518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.994689</td>\n",
       "      <td>0.330798</td>\n",
       "      <td>0.662744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cut_off  accuracy    recall  Performance\n",
       "0     0.10  0.299337  0.927757     0.613547\n",
       "1     0.15  0.797842  0.803232     0.800537\n",
       "2     0.20  0.967645  0.695342     0.831494\n",
       "3     0.25  0.983812  0.606464     0.795138\n",
       "4     0.30  0.987798  0.517586     0.752692\n",
       "5     0.35  0.990638  0.483840     0.737239\n",
       "6     0.40  0.992778  0.468631     0.730705\n",
       "7     0.45  0.993894  0.438213     0.716053\n",
       "8     0.50  0.994450  0.392586     0.693518\n",
       "9     0.55  0.994689  0.330798     0.662744"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "930ca61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetworks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/180 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8cbc126a4318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNN_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetworksResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/CreditCardsFraudDetection/Algorithm/EvaluateModels.py\u001b[0m in \u001b[0;36mNeuralNetworksResults\u001b[0;34m(X_test, X_train, Y_test, Y_train)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         NN_md.fit(X_train,tf.keras.utils.to_categorical(Y_train, num_classes = 2), epochs = 100,batch_size = 500,verbose = 0,\n\u001b[0;32m--> 107\u001b[0;31m             validation_data = (X_test,tf.keras.utils.to_categorical(Y_test,num_classes = 2)))\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mNN_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NN_results = em.NeuralNetworksResults(X_test, X_train, Y_test, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
